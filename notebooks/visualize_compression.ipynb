{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c595f442",
   "metadata": {},
   "source": [
    "# Visualize compression along irrelevant axis over training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "946b7198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import imageio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import Normalize\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91b87a2",
   "metadata": {},
   "source": [
    "#### Function for loading results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b751d713",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results(results_fn, rep_name, averaged=True):\n",
    "    \n",
    "    # Open file\n",
    "    results_dir = '../../results/'\n",
    "    results_path = os.path.join(results_dir,results_fn)\n",
    "    with open(results_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    analysis = data['analysis']\n",
    "    \n",
    "    # List with all results\n",
    "    params = [[s['get_orth_vis_params'][rep_name+'_ctx'] for s in run] for run in analysis]\n",
    "    \n",
    "    # Get useful variables (fixed across checkpoints/runs)\n",
    "    n_states = params[0][0]['n_states']\n",
    "    locs = params[0][0]['locs']\n",
    "    idx2loc = params[0][0]['idx2loc']\n",
    "    C_idxs = params[0][0]['C_idxs']\n",
    "    P_idxs = params[0][0]['P_idxs']\n",
    "    \n",
    "    # Mappings from indices to groups\n",
    "    idx2c = {}\n",
    "    for idx in range(n_states):\n",
    "        for c, group in enumerate(C_idxs):\n",
    "            if idx in group:\n",
    "                idx2c[idx] = c\n",
    "\n",
    "    idx2p = {}\n",
    "    for idx in range(n_states):\n",
    "        for p, group in enumerate(P_idxs):\n",
    "            if idx in group:\n",
    "                idx2p[idx] = p\n",
    "\n",
    "    # Get visualization parameters in context 0\n",
    "    alpha_0 = [[p['alpha_0'] for p in run] for run in params]\n",
    "    beta_0 = [[p['beta_0'] for p in run] for run in params]\n",
    "    alpha_0 = np.array(alpha_0) # [n_runs, n_checkpoints, n_params]\n",
    "    beta_0 = np.array(beta_0) # [n_runs, n_checkpoints, n_params]\n",
    "    \n",
    "    # Get visualization parameters in context 1\n",
    "    alpha_1 = [[p['alpha_1'] for p in run] for run in params]\n",
    "    beta_1 = [[p['beta_1'] for p in run] for run in params]\n",
    "    alpha_1 = np.array(alpha_1) # [n_runs, n_checkpoints, n_params]\n",
    "    beta_1 = np.array(beta_1) # [n_runs, n_checkpoints, n_params]\n",
    "    \n",
    "    # Get accuracy results\n",
    "    train_results = data['results']\n",
    "    train_accs = []\n",
    "    test_accs = []\n",
    "    for run in train_results:\n",
    "        train_accs.append([s['acc'] for s in run['train_accs']])\n",
    "        test_accs.append([s['acc'] for s in run['test_accs']])\n",
    "    \n",
    "    # Get regression with 1D rank differences\n",
    "    t_vals = []\n",
    "    for run in analysis:\n",
    "        t_vals.append([s['regression_with_1D'][rep_name]['categorical_regression']['t_statistic'][1] for s in run])\n",
    "    t_vals = np.array(t_vals)\n",
    "    \n",
    "    \n",
    "    # Average over runs\n",
    "    if averaged:\n",
    "        alpha_0 = np.mean(alpha_0, axis=0) # [n_checkpoints, n_params]\n",
    "        beta_0 = np.mean(beta_0, axis=0)   # [n_checkpoints, n_params]\n",
    "        alpha_1 = np.mean(alpha_1, axis=0) # [n_checkpoints, n_params]\n",
    "        beta_1 = np.mean(beta_1, axis=0)   # [n_checkpoints, n_params]\n",
    "        train_accs = np.mean(train_accs, axis=0)\n",
    "        test_accs = np.mean(test_accs, axis=0)\n",
    "        t_vals = np.mean(t_vals, axis=0)\n",
    "    else:\n",
    "        alpha_0 = alpha_0[0] # [n_checkpoints, n_params]\n",
    "        beta_0 = beta_0[0]   # [n_checkpoints, n_params]\n",
    "        alpha_1 = alpha_1[0] # [n_checkpoints, n_params]\n",
    "        beta_1 = beta_1[0]   # [n_checkpoints, n_params]\n",
    "        train_accs = np.array(train_accs[0])\n",
    "        test_accs = np.array(test_accs[0])\n",
    "        t_vals = t_vals[0] # [n_checkpoints]\n",
    "    \n",
    "    # Return results\n",
    "    results = {'n_states': n_states,\n",
    "               'locs': locs,\n",
    "               'idx2c': idx2c,\n",
    "               'idx2p': idx2p,\n",
    "               'alpha_0': alpha_0,\n",
    "               'beta_0': beta_0,\n",
    "               'alpha_1': alpha_1,\n",
    "               'beta_1': beta_1,\n",
    "               'train_accs': train_accs,\n",
    "               'test_accs': test_accs,\n",
    "               't_vals': t_vals}\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9be7e0",
   "metadata": {},
   "source": [
    "#### Function for reconstructing grid from params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b840f078",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_grid(alpha, beta, n_states, idx2c, idx2p):\n",
    "    n_params = len(alpha)\n",
    "    \n",
    "    # Cumulative sum \n",
    "    cum_alpha = np.zeros(n_params+1)\n",
    "    cum_beta = np.zeros(n_params+1)\n",
    "    cum_alpha[1:] = np.cumsum(alpha)\n",
    "    cum_beta[1:] = np.cumsum(beta)\n",
    "    \n",
    "    # Get x and y coordinates\n",
    "    X = np.zeros([n_states,2])\n",
    "    for idx in range(n_states):\n",
    "        c = idx2c[idx] # C group\n",
    "        p = idx2p[idx] # P group\n",
    "        X[idx,0] = cum_alpha[c] # x coordinate\n",
    "        X[idx,1] = cum_beta[p]  # y coordinate\n",
    "    \n",
    "    # Mean-center\n",
    "    X = X - np.mean(X, axis=0, keepdims=True)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41314e6d",
   "metadata": {},
   "source": [
    "#### Function for building .gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd0b45f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gif(results, model_name):\n",
    "    # Unpack results\n",
    "    n_states = results['n_states']\n",
    "    locs = results['locs']\n",
    "    idx2c = results['idx2c']\n",
    "    idx2p = results['idx2p']\n",
    "    alpha_0 = results['alpha_0']\n",
    "    beta_0 = results['beta_0']\n",
    "    alpha_1 = results['alpha_1']\n",
    "    beta_1 = results['beta_1']\n",
    "    train_accs = results['train_accs']\n",
    "    test_accs = results['test_accs']\n",
    "    t_vals = results['t_vals']\n",
    "    \n",
    "    # Reconstruct grid for each time point\n",
    "    n_steps = len(alpha_0)\n",
    "    reconstruction_0 = np.zeros([n_steps, n_states, 2])\n",
    "    for t, (alpha0_i, beta0_i) in enumerate(zip(alpha_0,beta_0)):\n",
    "        X_0 = reconstruct_grid(alpha0_i, beta0_i, n_states, idx2c, idx2p)\n",
    "        reconstruction_0[t,:,:] = X_0\n",
    "    reconstruction_1 = np.zeros([n_steps, n_states, 2])    \n",
    "    for t, (alpha1_i, beta1_i) in enumerate(zip(alpha_1,beta_1)):\n",
    "        X_1 = reconstruct_grid(alpha1_i, beta1_i, n_states, idx2c, idx2p)\n",
    "        reconstruction_1[t,:,:] = X_1\n",
    "    reconstruction = np.concatenate([reconstruction_0, reconstruction_1], axis=1)\n",
    "    \n",
    "    # Prepare to plot reconstruction\n",
    "    xmin = np.min(reconstruction[:,:,0])\n",
    "    xmax = np.max(reconstruction[:,:,0])\n",
    "    ymin = np.min(reconstruction[:,:,1])\n",
    "    ymax = np.max(reconstruction[:,:,1])\n",
    "    eps = 0.1*(np.max([xmax-xmin, ymax-ymin]))\n",
    "\n",
    "    t_vals_max = np.max(t_vals)\n",
    "    t_vals_min = np.min(t_vals)\n",
    "    \n",
    "    filenames = []\n",
    "    for t,M in enumerate(reconstruction):\n",
    "        fig, ax = plt.subplots(3, 1, \n",
    "                               figsize=[8,12], \n",
    "                               gridspec_kw={'height_ratios': [1,1,3]})\n",
    "\n",
    "        # Congruent vs. incongruent accuracies over time\n",
    "        ax[0].plot(train_accs[:t], c='tab:purple')\n",
    "        ax[0].plot(test_accs[:t], c='tab:orange')\n",
    "        ax[0].plot(t-1, train_accs[t-1], marker='o', c='tab:purple')\n",
    "        ax[0].plot(t-1, test_accs[t-1], marker='o', c='tab:orange')\n",
    "        ax[0].set_title(\"Train and test accuracy\")\n",
    "        ax[0].set_xlim([0,n_steps-1])\n",
    "        ax[0].set_ylim([-0.05,1.05])\n",
    "        ax[0].set_xlabel(\"Steps\")\n",
    "        ax[0].set_ylabel(\"Accuracy\")\n",
    "        ax[0].legend(['Train', 'Test'], loc='lower right')\n",
    "\n",
    "        # T statistic for 1D regression\n",
    "        ax[1].plot(t_vals[:t], c='tab:green')\n",
    "        ax[1].plot(t-1, t_vals[t-1], marker='o', c='tab:green')\n",
    "        ax[1].set_title(\"Compression along irrelevant axis\")\n",
    "        ax[1].set_xlim([0,n_steps-1])\n",
    "        ax[1].set_ylim([t_vals_min,t_vals_max])\n",
    "        ax[1].set_xlabel(\"Steps\")\n",
    "        ax[1].set_ylabel(\"T statistic\")\n",
    "\n",
    "        # Reconstructed grid\n",
    "        M_0 = M[:n_states] # context 0\n",
    "        scatter = ax[2].scatter(M_0[:,0], M_0[:,1], color='tab:red')\n",
    "        for loc,m in zip(locs,M_0):\n",
    "            ax[2].annotate(loc,m)\n",
    "        M_1 = M[n_states:] # context 1\n",
    "        scatter = ax[2].scatter(M_1[:,0], M_1[:,1], color='tab:blue')\n",
    "        for loc,m in zip(locs,M_1):\n",
    "            ax[2].annotate(loc,m)\n",
    "        main_title = \"{} Representations (reconstructed)\".format(model_name.upper())\n",
    "        ax[2].set_title(main_title)\n",
    "        ax[2].set_xlim([xmin-eps, xmax+eps])\n",
    "        ax[2].set_ylim([ymin-eps, ymax+eps])\n",
    "        ax[2].set_xticks([])\n",
    "        ax[2].set_yticks([])\n",
    "        ax[2].legend([\"Competence context\", \"Popularity context\"])\n",
    "\n",
    "        # Add grid lines\n",
    "        for (loc1, m1), (loc2, m2) in combinations(zip(locs, M_0), 2):\n",
    "            x1, y1 = loc1\n",
    "            x2, y2 = loc2\n",
    "            one_up = x1-x2 == 0 and abs(y1-y2) == 1\n",
    "            one_over = y1-y2 == 0 and abs(x1-x2) == 1\n",
    "            if one_up or one_over:\n",
    "                xx = [m1[0], m2[0]]\n",
    "                yy = [m1[1], m2[1]]\n",
    "                ax[2].plot(xx, yy, '--', color='tab:red')    \n",
    "        for (loc1, m1), (loc2, m2) in combinations(zip(locs, M_1), 2):\n",
    "            x1, y1 = loc1\n",
    "            x2, y2 = loc2\n",
    "            one_up = x1-x2 == 0 and abs(y1-y2) == 1\n",
    "            one_over = y1-y2 == 0 and abs(x1-x2) == 1\n",
    "            if one_up or one_over:\n",
    "                xx = [m1[0], m2[0]]\n",
    "                yy = [m1[1], m2[1]]\n",
    "                ax[2].plot(xx, yy, '--', color='tab:blue') \n",
    "\n",
    "        plt.tight_layout()\n",
    "        filename = '../../results/visualize_compression_{}{}.png'.format(model_name, t)\n",
    "        filenames.append(filename)\n",
    "\n",
    "        # More time on first and last frames\n",
    "        if t == n_steps-1:\n",
    "            for extra_time in range(40):\n",
    "                filenames.append(filename)\n",
    "        plt.savefig(filename, dpi=100)\n",
    "        plt.close()\n",
    "        \n",
    "    # Write .gif\n",
    "    gif_name = 'visualize_reconstructed_compression_{}.gif'.format(model_name)\n",
    "    with imageio.get_writer(gif_name, mode='I') as writer:\n",
    "        for filename in filenames:\n",
    "            image = imageio.imread(filename)\n",
    "            writer.append_data(image)\n",
    "    \n",
    "    # remove files\n",
    "    for filename in set(filenames):\n",
    "        if os.path.isfile(filename):\n",
    "            os.remove(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb97a9a",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdc68f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_fn = 'mlp.P'\n",
    "rep_name = 'hidden'\n",
    "model_name = 'MLP0'\n",
    "averaged = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ebad962",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = load_results(results_fn, rep_name, averaged)\n",
    "build_gif(results, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d05d87f",
   "metadata": {},
   "source": [
    "<img src=\"visualize_reconstructed_compression_MLP0.gif\" width=\"750\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36dc349",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6b3ef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_fn = 'rnn.P'\n",
    "rep_name = 'average'\n",
    "model_name = 'RNN0'\n",
    "averaged = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a82dc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = load_results(results_fn, rep_name, averaged)\n",
    "build_gif(results, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee62b6b8",
   "metadata": {},
   "source": [
    "<img src=\"visualize_reconstructed_compression_RNN0.gif\" width=\"750\" align=\"center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c2e533",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
